{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso,LassoLars,ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation, linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.lda import LDA\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bike_sharing_demand = pd.read_csv('./data/input/train.csv')\n",
    "prediction_data = pd.read_csv('data/input/test.csv')\n",
    "train_data, train_labels = bike_sharing_demand.ix[:, 'datetime':'windspeed'], bike_sharing_demand.ix[:, 'casual':]\n",
    "prediction_data = prediction_data.ix[:, 'datetime':'windspeed']\n",
    "np.random.seed(0)\n",
    "shuffle = np.random.permutation(np.arange(train_data.shape[0]))\n",
    "mini_bike_sharing = bike_sharing_demand.ix[shuffle[:100], :]\n",
    "mini_train_data, mini_train_labels = mini_bike_sharing.ix[:, 'datetime':'windspeed'], mini_bike_sharing.ix[:, 'casual':]\n",
    "# Let's extract the information\n",
    "for dataset in (train_data, prediction_data):\n",
    "    dataset['hour'] = dataset['datetime'].map(lambda x: (datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\")).hour)\n",
    "    dataset['weekday'] = dataset['datetime'].map(lambda x: (datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\")).weekday())\n",
    "    dataset['month'] = dataset['datetime'].map(lambda x: (datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\")).month)\n",
    "    dataset['year'] = dataset['datetime'].map(lambda x: (datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\")).year)\n",
    "\n",
    "cv = cross_validation.ShuffleSplit(train_data.shape[0], n_iter=10, random_state=0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the Root-Mean-Squared-Log Error function for scoring predictions\n",
    "def rmsle(actual_values, predicted_values):\n",
    "    squared_log_errors = (np.log(np.array(predicted_values) + 1) - np.log(np.array(actual_values) + 1)) ** 2\n",
    "    mean_squared_errors = np.nansum(squared_log_errors) / len(squared_log_errors)\n",
    "    return np.sqrt(mean_squared_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_predict(model,clf):\n",
    "    train_scores,test_scores =[],[]\n",
    "    for i, (train_index, test_index) in enumerate(cv):\n",
    "        x_train, y_train = train_data.ix[train_index, 'season':], train_labels.ix[train_index, 'count']\n",
    "        x_test, y_test = train_data.ix[test_index, 'season':], train_labels.ix[test_index, 'count']\n",
    "        clf.fit(x_train, y_train)\n",
    "        predicted_values = clf.predict(x_test)\n",
    "        rmse_score =rmsle(y_test, predicted_values)\n",
    "        train_score = clf.score(x_train, y_train)\n",
    "        test_score = clf.score(x_test, y_test)\n",
    "        print(\"%s : Loop: %d,RMSLE: %.3f,Train Score %.3f,Test Score %.3f\" %(model,i, rmsle(y_test, predicted_values),train_score,test_score))\n",
    "        train_scores.append(train_score)\n",
    "        test_scores.append(test_score)\n",
    "    #print scores\n",
    "    #print [score for score in scores]\n",
    "    print(\"Mean Train Score for %s %.3f , Mean Test Score %.3f\" % (model,np.mean(train_scores),np.mean(test_scores)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA : Loop: 0,RMSLE: 1.600,Train Score 0.049,Test Score 0.023\n",
      "LDA : Loop: 1,RMSLE: 1.539,Train Score 0.049,Test Score 0.022\n",
      "LDA : Loop: 2,RMSLE: 1.644,Train Score 0.049,Test Score 0.021\n",
      "LDA : Loop: 3,RMSLE: 1.620,Train Score 0.049,Test Score 0.018\n",
      "LDA : Loop: 4,RMSLE: 1.546,Train Score 0.048,Test Score 0.021\n",
      "LDA : Loop: 5,RMSLE: 1.649,Train Score 0.052,Test Score 0.019\n",
      "LDA : Loop: 6,RMSLE: 1.610,Train Score 0.049,Test Score 0.018\n",
      "LDA : Loop: 7,RMSLE: 1.649,Train Score 0.049,Test Score 0.022\n",
      "LDA : Loop: 8,RMSLE: 1.604,Train Score 0.052,Test Score 0.016\n",
      "LDA : Loop: 9,RMSLE: 1.608,Train Score 0.048,Test Score 0.020\n",
      "Mean Train Score for LDA 0.049 , Mean Test Score 0.020\n"
     ]
    }
   ],
   "source": [
    "clf_lda = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('normalizer', Normalizer()),\n",
    "    ('model', LDA())\n",
    "])\n",
    "\n",
    "train_predict('LDA',clf_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear  : Loop: 0,RMSLE: 1.155,Train Score 0.393,Test Score 0.397\n",
      "Linear  : Loop: 1,RMSLE: 1.173,Train Score 0.387,Test Score 0.424\n",
      "Linear  : Loop: 2,RMSLE: 1.155,Train Score 0.399,Test Score 0.373\n",
      "Linear  : Loop: 3,RMSLE: 1.168,Train Score 0.397,Test Score 0.381\n",
      "Linear  : Loop: 4,RMSLE: 1.124,Train Score 0.388,Test Score 0.414\n",
      "Linear  : Loop: 5,RMSLE: 1.137,Train Score 0.399,Test Score 0.373\n",
      "Linear  : Loop: 6,RMSLE: 1.160,Train Score 0.393,Test Score 0.397\n",
      "Linear  : Loop: 7,RMSLE: 1.168,Train Score 0.397,Test Score 0.380\n",
      "Linear  : Loop: 8,RMSLE: 1.115,Train Score 0.393,Test Score 0.394\n",
      "Linear  : Loop: 9,RMSLE: 1.162,Train Score 0.399,Test Score 0.373\n",
      "Mean Train Score for Linear  0.395 , Mean Test Score 0.391\n"
     ]
    }
   ],
   "source": [
    "clf_linear = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('normalizer', Normalizer()),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "train_predict('Linear ',clf_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Polynomial Regression with degree 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Regression degree 3  : Loop: 0,RMSLE: 0.970,Train Score 0.659,Test Score 0.611\n",
      "Polynomial Regression degree 3  : Loop: 1,RMSLE: 0.986,Train Score 0.654,Test Score 0.636\n",
      "Polynomial Regression degree 3  : Loop: 2,RMSLE: 0.970,Train Score 0.663,Test Score 0.586\n",
      "Polynomial Regression degree 3  : Loop: 3,RMSLE: 0.981,Train Score 0.659,Test Score 0.618\n",
      "Polynomial Regression degree 3  : Loop: 4,RMSLE: 0.924,Train Score 0.656,Test Score 0.623\n",
      "Polynomial Regression degree 3  : Loop: 5,RMSLE: 0.912,Train Score 0.660,Test Score 0.600\n",
      "Polynomial Regression degree 3  : Loop: 6,RMSLE: 0.968,Train Score 0.662,Test Score 0.597\n",
      "Polynomial Regression degree 3  : Loop: 7,RMSLE: 0.967,Train Score 0.658,Test Score 0.621\n",
      "Polynomial Regression degree 3  : Loop: 8,RMSLE: 0.978,Train Score 0.657,Test Score 0.621\n",
      "Polynomial Regression degree 3  : Loop: 9,RMSLE: 0.969,Train Score 0.660,Test Score 0.607\n",
      "Mean Train Score for Polynomial Regression degree 3  0.659 , Mean Test Score 0.612\n"
     ]
    }
   ],
   "source": [
    "clf_poly = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('normalizer', Normalizer()),\n",
    "    ('poly', PolynomialFeatures(degree=3)),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "train_predict('Polynomial Regression degree 3 ',clf_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#KNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN  : Loop: 0,RMSLE: 0.899,Train Score 0.763,Test Score 0.607\n",
      "KNN  : Loop: 1,RMSLE: 0.906,Train Score 0.756,Test Score 0.649\n",
      "KNN  : Loop: 2,RMSLE: 0.897,Train Score 0.762,Test Score 0.603\n",
      "KNN  : Loop: 3,RMSLE: 0.890,Train Score 0.757,Test Score 0.616\n",
      "KNN  : Loop: 4,RMSLE: 0.864,Train Score 0.752,Test Score 0.637\n",
      "KNN  : Loop: 5,RMSLE: 0.879,Train Score 0.759,Test Score 0.613\n",
      "KNN  : Loop: 6,RMSLE: 0.899,Train Score 0.758,Test Score 0.595\n",
      "KNN  : Loop: 7,RMSLE: 0.891,Train Score 0.760,Test Score 0.627\n",
      "KNN  : Loop: 8,RMSLE: 0.865,Train Score 0.758,Test Score 0.621\n",
      "KNN  : Loop: 9,RMSLE: 0.903,Train Score 0.757,Test Score 0.618\n",
      "Mean Train Score for KNN  0.758 , Mean Test Score 0.618\n"
     ]
    }
   ],
   "source": [
    "clf_knn = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('normalizer', Normalizer()),\n",
    "    ('model', KNeighborsRegressor(n_neighbors=5))\n",
    "])\n",
    "train_predict('KNN ',clf_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression with polynomial features with degree 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge-degree 3 : Loop: 0,RMSLE: 0.986,Train Score 0.637,Test Score 0.616\n",
      "Ridge-degree 3 : Loop: 1,RMSLE: 1.001,Train Score 0.632,Test Score 0.637\n",
      "Ridge-degree 3 : Loop: 2,RMSLE: 0.949,Train Score 0.640,Test Score 0.597\n",
      "Ridge-degree 3 : Loop: 3,RMSLE: 1.008,Train Score 0.637,Test Score 0.611\n",
      "Ridge-degree 3 : Loop: 4,RMSLE: 0.939,Train Score 0.634,Test Score 0.622\n",
      "Ridge-degree 3 : Loop: 5,RMSLE: 0.940,Train Score 0.638,Test Score 0.608\n",
      "Ridge-degree 3 : Loop: 6,RMSLE: 0.965,Train Score 0.639,Test Score 0.606\n",
      "Ridge-degree 3 : Loop: 7,RMSLE: 0.986,Train Score 0.635,Test Score 0.623\n",
      "Ridge-degree 3 : Loop: 8,RMSLE: 0.966,Train Score 0.635,Test Score 0.614\n",
      "Ridge-degree 3 : Loop: 9,RMSLE: 0.978,Train Score 0.638,Test Score 0.602\n",
      "Mean Train Score for Ridge-degree 3 0.637 , Mean Test Score 0.614\n"
     ]
    }
   ],
   "source": [
    "clf_ridge = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('normalizer', Normalizer()),\n",
    "    ('poly', PolynomialFeatures(degree=3)),\n",
    "    ('model', Ridge(alpha=0.5, copy_X=True, fit_intercept=True, max_iter=None,\n",
    "                    normalize=False, solver='auto', tol=0.001))\n",
    "])\n",
    "train_predict('Ridge-degree 3',clf_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso with Polynomial features with degree 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso-degree 3 : Loop: 0,RMSLE: 1.013,Train Score 0.598,Test Score 0.593\n",
      "Lasso-degree 3 : Loop: 1,RMSLE: 1.028,Train Score 0.592,Test Score 0.619\n",
      "Lasso-degree 3 : Loop: 2,RMSLE: 0.982,Train Score 0.600,Test Score 0.579\n",
      "Lasso-degree 3 : Loop: 3,RMSLE: 0.982,Train Score 0.599,Test Score 0.591\n",
      "Lasso-degree 3 : Loop: 4,RMSLE: 0.974,Train Score 0.595,Test Score 0.602\n",
      "Lasso-degree 3 : Loop: 5,RMSLE: 0.967,Train Score 0.600,Test Score 0.578\n",
      "Lasso-degree 3 : Loop: 6,RMSLE: 1.012,Train Score 0.600,Test Score 0.586\n",
      "Lasso-degree 3 : Loop: 7,RMSLE: 1.017,Train Score 0.597,Test Score 0.591\n",
      "Lasso-degree 3 : Loop: 8,RMSLE: 1.007,Train Score 0.596,Test Score 0.592\n",
      "Lasso-degree 3 : Loop: 9,RMSLE: 1.033,Train Score 0.601,Test Score 0.581\n",
      "Mean Train Score for Lasso-degree 3 0.598 , Mean Test Score 0.591\n"
     ]
    }
   ],
   "source": [
    "clf_lasso = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('normalizer', Normalizer()),\n",
    "    ('poly', PolynomialFeatures(degree=3)),\n",
    "    ('model', Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
    "                    normalize=False, positive=False, precompute=False,\n",
    "                    tol=0.0001, warm_start=False))\n",
    "])\n",
    "train_predict('Lasso-degree 3',clf_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Lasso Lars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso-lars 3 : Loop: 0,RMSLE: 1.012,Train Score 0.598,Test Score 0.593\n",
      "Lasso-lars 3 : Loop: 1,RMSLE: 1.028,Train Score 0.592,Test Score 0.619\n",
      "Lasso-lars 3 : Loop: 2,RMSLE: 0.982,Train Score 0.600,Test Score 0.579\n",
      "Lasso-lars 3 : Loop: 3,RMSLE: 0.982,Train Score 0.599,Test Score 0.591\n",
      "Lasso-lars 3 : Loop: 4,RMSLE: 0.974,Train Score 0.595,Test Score 0.601\n",
      "Lasso-lars 3 : Loop: 5,RMSLE: 0.967,Train Score 0.600,Test Score 0.578\n",
      "Lasso-lars 3 : Loop: 6,RMSLE: 1.012,Train Score 0.600,Test Score 0.586\n",
      "Lasso-lars 3 : Loop: 7,RMSLE: 1.017,Train Score 0.597,Test Score 0.591\n",
      "Lasso-lars 3 : Loop: 8,RMSLE: 1.002,Train Score 0.596,Test Score 0.592\n",
      "Lasso-lars 3 : Loop: 9,RMSLE: 1.037,Train Score 0.601,Test Score 0.581\n",
      "Mean Train Score for Lasso-lars 3 0.598 , Mean Test Score 0.591\n"
     ]
    }
   ],
   "source": [
    "clf_lassolars = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('normalizer', Normalizer()),\n",
    "    ('poly', PolynomialFeatures(degree=3)),\n",
    "    ('model', LassoLars(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
    "                    normalize=False, precompute=False))\n",
    "])\n",
    "train_predict('Lasso-lars 3',clf_lassolars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic Net : Loop: 0,RMSLE: 1.258,Train Score 0.418,Test Score 0.417\n",
      "Elastic Net : Loop: 1,RMSLE: 1.257,Train Score 0.411,Test Score 0.445\n",
      "Elastic Net : Loop: 2,RMSLE: 1.239,Train Score 0.422,Test Score 0.402\n",
      "Elastic Net : Loop: 3,RMSLE: 1.240,Train Score 0.421,Test Score 0.406\n",
      "Elastic Net : Loop: 4,RMSLE: 1.224,Train Score 0.413,Test Score 0.430\n",
      "Elastic Net : Loop: 5,RMSLE: 1.213,Train Score 0.423,Test Score 0.401\n",
      "Elastic Net : Loop: 6,RMSLE: 1.246,Train Score 0.417,Test Score 0.420\n",
      "Elastic Net : Loop: 7,RMSLE: 1.247,Train Score 0.420,Test Score 0.407\n",
      "Elastic Net : Loop: 8,RMSLE: 1.221,Train Score 0.418,Test Score 0.408\n",
      "Elastic Net : Loop: 9,RMSLE: 1.255,Train Score 0.422,Test Score 0.406\n",
      "Mean Train Score for Elastic Net 0.418 , Mean Test Score 0.414\n"
     ]
    }
   ],
   "source": [
    "clf_elastic_net = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('normalizer', Normalizer()),\n",
    "    ('poly', PolynomialFeatures(degree=3)),\n",
    "    ('model', ElasticNet(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
    "                    normalize=False, precompute=False))\n",
    "])\n",
    "train_predict('Elastic Net',clf_elastic_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # Support Vector Regression - RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR - RBF : Loop: 0,RMSLE: 0.943,Train Score 0.512,Test Score 0.510\n",
      "SVR - RBF : Loop: 1,RMSLE: 0.966,Train Score 0.504,Test Score 0.551\n",
      "SVR - RBF : Loop: 2,RMSLE: 0.941,Train Score 0.518,Test Score 0.476\n",
      "SVR - RBF : Loop: 3,RMSLE: 0.929,Train Score 0.516,Test Score 0.496\n",
      "SVR - RBF : Loop: 4,RMSLE: 0.905,Train Score 0.507,Test Score 0.510\n",
      "SVR - RBF : Loop: 5,RMSLE: 0.907,Train Score 0.516,Test Score 0.493\n",
      "SVR - RBF : Loop: 6,RMSLE: 0.923,Train Score 0.512,Test Score 0.509\n",
      "SVR - RBF : Loop: 7,RMSLE: 0.947,Train Score 0.510,Test Score 0.500\n",
      "SVR - RBF : Loop: 8,RMSLE: 0.932,Train Score 0.515,Test Score 0.484\n",
      "SVR - RBF : Loop: 9,RMSLE: 0.955,Train Score 0.517,Test Score 0.507\n",
      "Mean Train Score for SVR - RBF 0.513 , Mean Test Score 0.504\n"
     ]
    }
   ],
   "source": [
    "clf_svrbf = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('normalizer', Normalizer()),\n",
    "    ('model', SVR(kernel='rbf', C=1e3, gamma=0.1))\n",
    "])\n",
    "train_predict('SVR - RBF',clf_svrbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Support Vector Regression - Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR - Linear kernel : Loop: 0,RMSLE: 1.070,Train Score 0.335,Test Score 0.336\n",
      "SVR - Linear kernel : Loop: 1,RMSLE: 1.080,Train Score 0.325,Test Score 0.374\n",
      "SVR - Linear kernel : Loop: 2,RMSLE: 1.064,Train Score 0.344,Test Score 0.317\n",
      "SVR - Linear kernel : Loop: 3,RMSLE: 1.079,Train Score 0.342,Test Score 0.332\n",
      "SVR - Linear kernel : Loop: 4,RMSLE: 1.031,Train Score 0.329,Test Score 0.347\n",
      "SVR - Linear kernel : Loop: 5,RMSLE: 1.048,Train Score 0.343,Test Score 0.311\n",
      "SVR - Linear kernel : Loop: 6,RMSLE: 1.072,Train Score 0.332,Test Score 0.337\n",
      "SVR - Linear kernel : Loop: 7,RMSLE: 1.089,Train Score 0.342,Test Score 0.325\n",
      "SVR - Linear kernel : Loop: 8,RMSLE: 1.038,Train Score 0.340,Test Score 0.321\n",
      "SVR - Linear kernel : Loop: 9,RMSLE: 1.076,Train Score 0.344,Test Score 0.335\n",
      "Mean Train Score for SVR - Linear kernel 0.338 , Mean Test Score 0.333\n"
     ]
    }
   ],
   "source": [
    "clf_svrlin = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('normalizer', Normalizer()),\n",
    "    ('model', SVR(kernel='linear', C=1e3))\n",
    "])\n",
    "train_predict('SVR - Linear kernel',clf_svrlin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Support Vector Regression - Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR - Polynomial kernel : Loop: 0,RMSLE: 1.145,Train Score 0.284,Test Score 0.280\n",
      "SVR - Polynomial kernel : Loop: 1,RMSLE: 1.135,Train Score 0.276,Test Score 0.317\n",
      "SVR - Polynomial kernel : Loop: 2,RMSLE: 1.132,Train Score 0.292,Test Score 0.273\n",
      "SVR - Polynomial kernel : Loop: 3,RMSLE: 1.140,Train Score 0.290,Test Score 0.285\n",
      "SVR - Polynomial kernel : Loop: 4,RMSLE: 1.115,Train Score 0.278,Test Score 0.281\n",
      "SVR - Polynomial kernel : Loop: 5,RMSLE: 1.106,Train Score 0.290,Test Score 0.263\n",
      "SVR - Polynomial kernel : Loop: 6,RMSLE: 1.143,Train Score 0.282,Test Score 0.284\n",
      "SVR - Polynomial kernel : Loop: 7,RMSLE: 1.140,Train Score 0.289,Test Score 0.281\n",
      "SVR - Polynomial kernel : Loop: 8,RMSLE: 1.120,Train Score 0.288,Test Score 0.262\n",
      "SVR - Polynomial kernel : Loop: 9,RMSLE: 1.138,Train Score 0.289,Test Score 0.291\n",
      "Mean Train Score for SVR - Polynomial kernel 0.286 , Mean Test Score 0.282\n"
     ]
    }
   ],
   "source": [
    "clf_svrpoly = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('normalizer', Normalizer()),\n",
    "    ('model', SVR(kernel='poly', C=1e3, degree=3))\n",
    "])\n",
    "train_predict('SVR - Polynomial kernel',clf_svrpoly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Regressor : Loop: 0,RMSLE: 0.428,Train Score 0.987,Test Score 0.909\n",
      "RF Regressor : Loop: 1,RMSLE: 0.428,Train Score 0.987,Test Score 0.917\n",
      "RF Regressor : Loop: 2,RMSLE: 0.418,Train Score 0.987,Test Score 0.898\n",
      "RF Regressor : Loop: 3,RMSLE: 0.409,Train Score 0.987,Test Score 0.909\n",
      "RF Regressor : Loop: 4,RMSLE: 0.404,Train Score 0.988,Test Score 0.898\n",
      "RF Regressor : Loop: 5,RMSLE: 0.400,Train Score 0.987,Test Score 0.921\n",
      "RF Regressor : Loop: 6,RMSLE: 0.429,Train Score 0.987,Test Score 0.904\n",
      "RF Regressor : Loop: 7,RMSLE: 0.433,Train Score 0.987,Test Score 0.904\n",
      "RF Regressor : Loop: 8,RMSLE: 0.421,Train Score 0.987,Test Score 0.918\n",
      "RF Regressor : Loop: 9,RMSLE: 0.436,Train Score 0.987,Test Score 0.905\n",
      "Mean Train Score for RF Regressor 0.987 , Mean Test Score 0.908\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(random_state=0, n_estimators=100)\n",
    "clf_rf = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('normalizer', Normalizer()),\n",
    "    ('model', rf)\n",
    "])\n",
    "train_predict('RF Regressor',clf_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ExtraTree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Tre Regressor : Loop: 0,RMSLE: 0.441,Train Score 1.000,Test Score 0.912\n",
      "Extra Tre Regressor : Loop: 1,RMSLE: 0.435,Train Score 1.000,Test Score 0.925\n",
      "Extra Tre Regressor : Loop: 2,RMSLE: 0.414,Train Score 1.000,Test Score 0.906\n",
      "Extra Tre Regressor : Loop: 3,RMSLE: 0.421,Train Score 1.000,Test Score 0.920\n",
      "Extra Tre Regressor : Loop: 4,RMSLE: 0.409,Train Score 1.000,Test Score 0.911\n",
      "Extra Tre Regressor : Loop: 5,RMSLE: 0.400,Train Score 1.000,Test Score 0.926\n",
      "Extra Tre Regressor : Loop: 6,RMSLE: 0.433,Train Score 1.000,Test Score 0.913\n",
      "Extra Tre Regressor : Loop: 7,RMSLE: 0.425,Train Score 1.000,Test Score 0.917\n",
      "Extra Tre Regressor : Loop: 8,RMSLE: 0.418,Train Score 1.000,Test Score 0.916\n",
      "Extra Tre Regressor : Loop: 9,RMSLE: 0.425,Train Score 1.000,Test Score 0.916\n",
      "Mean Train Score for Extra Tre Regressor 1.000 , Mean Test Score 0.916\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "etr = ExtraTreesRegressor(random_state=0, n_estimators=100)\n",
    "clf_etr = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('normalizer', Normalizer()),\n",
    "    ('model', etr)\n",
    "])\n",
    "train_predict('Extra Tre Regressor',clf_etr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost : Loop: 0,RMSLE: 1.274,Train Score 0.527,Test Score 0.511\n",
      "Adaboost : Loop: 1,RMSLE: 1.331,Train Score 0.504,Test Score 0.497\n",
      "Adaboost : Loop: 2,RMSLE: 1.370,Train Score 0.482,Test Score 0.475\n",
      "Adaboost : Loop: 3,RMSLE: 1.336,Train Score 0.507,Test Score 0.489\n",
      "Adaboost : Loop: 4,RMSLE: 1.397,Train Score 0.429,Test Score 0.443\n",
      "Adaboost : Loop: 5,RMSLE: 1.368,Train Score 0.457,Test Score 0.443\n",
      "Adaboost : Loop: 6,RMSLE: 1.376,Train Score 0.506,Test Score 0.478\n",
      "Adaboost : Loop: 7,RMSLE: 1.399,Train Score 0.459,Test Score 0.429\n",
      "Adaboost : Loop: 8,RMSLE: 1.462,Train Score 0.372,Test Score 0.429\n",
      "Adaboost : Loop: 9,RMSLE: 1.353,Train Score 0.494,Test Score 0.450\n",
      "Mean Train Score for Adaboost 0.474 , Mean Test Score 0.464\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "adaboost = AdaBoostRegressor()\n",
    "clf_ada = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('normalizer', Normalizer()),\n",
    "    ('model', adaboost)\n",
    "])\n",
    "train_predict('Adaboost',clf_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boost : Loop: 0,RMSLE: 0.763,Train Score 0.824,Test Score 0.796\n",
      "Gradient Boost : Loop: 1,RMSLE: 0.770,Train Score 0.822,Test Score 0.817\n",
      "Gradient Boost : Loop: 2,RMSLE: 0.736,Train Score 0.824,Test Score 0.799\n",
      "Gradient Boost : Loop: 3,RMSLE: 0.745,Train Score 0.821,Test Score 0.794\n",
      "Gradient Boost : Loop: 4,RMSLE: 0.752,Train Score 0.828,Test Score 0.813\n",
      "Gradient Boost : Loop: 5,RMSLE: 0.733,Train Score 0.822,Test Score 0.801\n",
      "Gradient Boost : Loop: 6,RMSLE: 0.746,Train Score 0.824,Test Score 0.793\n",
      "Gradient Boost : Loop: 7,RMSLE: 0.754,Train Score 0.828,Test Score 0.799\n",
      "Gradient Boost : Loop: 8,RMSLE: 0.735,Train Score 0.821,Test Score 0.805\n",
      "Gradient Boost : Loop: 9,RMSLE: 0.759,Train Score 0.827,Test Score 0.798\n",
      "Mean Train Score for Gradient Boost 0.824 , Mean Test Score 0.802\n"
     ]
    }
   ],
   "source": [
    "gbm = GradientBoostingRegressor(loss='ls', alpha=0.95, n_estimators=500, max_depth=4, learning_rate=.01,\n",
    "                                min_samples_leaf=9, min_samples_split=9)\n",
    "\n",
    "clf_gbm = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('normalizer', Normalizer()),\n",
    "    ('model', gbm)\n",
    "])\n",
    "train_predict('Gradient Boost',clf_gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For now train using the RF model on the entire training set\n",
    "rf = ExtraTreesRegressor(random_state=0)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "param_grid = {'n_estimators': [100, 300, 500, 700, 1000], 'max_depth': [None, 1, 2, 3, 5], 'min_samples_split': [1, 2, 3, 5]}\n",
    "model = GridSearchCV(rf, param_grid=param_grid)\n",
    "model.fit(train_data.ix[:, 'season':], train_labels.ix[:, 'count'])\n",
    "\n",
    "# Make predictions\n",
    "prediction_values = model.predict(prediction_data.ix[:, 'season':])\n",
    "\n",
    "# Create submission from sample_submission file\n",
    "submission_df = pd.read_csv('./data/output/sampleSubmission.csv')\n",
    "submission_df['count'] = prediction_values\n",
    "submission_df.to_csv('./data/output/rf_tuned_windowedfeatures.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
